---
layout: post
title:      "necessity of the AI code of hammurabi"
date:       2017-12-05 14:37:40 -0500
permalink:  future_of_ai_friend_or_foe
---


there was a [highly publicized debate between elon musk and mark zuckerberg](https://futurism.com/bill-gates-says-we-shouldnt-panic-about-artificial-intelligence/) on the topic of AI back in july. basically, elon musk thinks there is an existential risk for human civilization as opposed to mark zuckerberg who thinks that way of thought is irresponsible fear-mongering. other tech all-stars include bill gates, who is in the middle of the two polar ends, and michael dell, who is on team zuckerberg.

most of the articles regarding this debate or the topic of AI translates this existential risk into humans losing jobs to AI powered robots and/or exaggerated sci-fi movie scenarios involving killer robots, but i strongly believe that it's irresponsible to limit the potential risk of AI to such limited scopes.

the focus rests primarily on the intent of AI, when in fact, it's the humans we have to watch out for. there will always be the few that ruins it for the many and especially in a world driven by monetary gain, i find it really difficult to trust an unregulated goldmine to humanity. history has proven time and again that we, as humans, are capable of doing good, but at the same time are capable of doing very evil things.

for example, the internet has provided us with the ability to access, exchange, and communicate a plethora of information. although such access allows us to use it to connect with family and friends, find research papers to aid in scientific research, or contribute to creative growth, however, there are those who use it to research how to murder someone or find child pornography. the discovery of electricity has allowed us to provide lighting to households, allowing uninterrupted productivity regardless of whether it's day or night, but at the same time has become a necessary utlity monopolized by companies driven by profit.

on the contrary, the potential for AI to deliver benefits is unquestionable and the rate of advancement is very promising. for that reason, i think that it is important to begin considering placing safeguards to protect such promising technology from falling into the wrong hands. 

even though due to the imperfection of human inventions, any policy governing such inventions won't prevent bad things from happening, that sometimes regardless of how careful we are, it only takes one anomaly to set off a major disaster or ignite an unforeseen event (just like in life), don't we owe eachother the duty as human beings to cover all our bases for the risks that we can prevent? it seems very impulsive and overconfident to believe any invention of ours won't have any negative consequences.
